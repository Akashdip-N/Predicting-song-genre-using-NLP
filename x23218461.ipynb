{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/adn-\n",
      "[nltk_data]     mbp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import functions\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# For XG-Boost\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "print(xgb.__version__)\n",
    "\n",
    "# Used for callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Used for comparing RNN and CNN\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the train and test data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train_data, test_data], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the dataset's index after removing duplicates\n",
    "\n",
    "new_dataset.index = range(new_dataset.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rock', 'Metal', 'Pop', 'Indie', 'R&B', 'Hip-Hop', 'Country',\n",
       "       'Jazz', 'Electronic', 'Folk'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['Genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = new_dataset[\n",
    "    (new_dataset['Genre'] == 'Hip-Hop') |\n",
    "    (new_dataset['Genre'] == 'Pop') |\n",
    "    (new_dataset['Genre'] == 'Country') |\n",
    "    (new_dataset['Genre'] == 'Rock') |\n",
    "    (new_dataset['Genre'] == 'Electronic')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset['Lyrics'] = new_dataset['Lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset['Lyrics'] = functions.clean_data(new_dataset['Lyrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing songs with no lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = new_dataset.drop(\n",
    "    new_dataset[new_dataset['Lyrics'].str.len() == 0].index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping the data by artist and genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "Country        810\n",
       "Electronic     660\n",
       "Hip-Hop        960\n",
       "Pop           2557\n",
       "Rock          6940\n",
       "Name: Song, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.groupby('Genre')['Song'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_songs = min(new_dataset.groupby('Genre')['Song'].count())\n",
    "minimum_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in new_dataset['Genre'].unique():\n",
    "  if new_dataset[new_dataset['Genre'] == genre]['Song'].size < (2 * minimum_songs):\n",
    "    data_copy = new_dataset[new_dataset['Genre'] == genre].copy() # copy songs of genres with low number of songs\n",
    "    new_dataset = pd.concat([new_dataset, data_copy], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.index = range(new_dataset.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in new_dataset['Genre'].unique():\n",
    "  maxID = new_dataset[new_dataset['Genre'] == genre].index[2 * minimum_songs - 1]\n",
    "  new_dataset = new_dataset.drop(new_dataset[(new_dataset['Genre'] == genre) & (new_dataset.index > maxID)].index) # remove songs of genres with too much songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "Country       1320\n",
       "Electronic    1320\n",
       "Hip-Hop       1320\n",
       "Pop           1320\n",
       "Rock          1320\n",
       "Name: Song, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.groupby('Genre')['Song'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and removal of unnecessary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset['Lyrics'] = functions.split_data(new_dataset['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "new_songs = []\n",
    "for value in new_dataset['Lyrics']:\n",
    "  value = [w for w in value if not w in stop_words]\n",
    "  new_songs.append(value)\n",
    "new_dataset['Lyrics'] = new_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[starts, pain, , followed, hate, fueled, endle...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freedom, , alone, alone, patiently, waiting, ...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[biting, hand, feeds, , lying, voice, inside, ...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[say, know, cant, imagine, waits, across, line...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[heart, beating, faster, cant, control, feelin...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Lyrics Genre\n",
       "0  [starts, pain, , followed, hate, fueled, endle...  Rock\n",
       "1  [freedom, , alone, alone, patiently, waiting, ...  Rock\n",
       "2  [biting, hand, feeds, , lying, voice, inside, ...  Rock\n",
       "3  [say, know, cant, imagine, waits, across, line...  Rock\n",
       "4  [heart, beating, faster, cant, control, feelin...  Rock"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = new_dataset[['Lyrics', 'Genre']]\n",
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.to_csv('clean_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\n",
    "    'clean_data.csv',\n",
    "    converters = {\n",
    "        'Lyrics': literal_eval\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = dataset['Lyrics']\n",
    "genre = dataset['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lyrics, genre, test_size=0.25, random_state=42, stratify = genre)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3712,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3712,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1238,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1238,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1650,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1650,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "display(y_train.shape)\n",
    "display(X_val.shape)\n",
    "display(y_val.shape)\n",
    "display(X_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemeting tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = functions.create_vocab(X_train, 10000)\n",
    "stopwords_len = len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to each word assigns a ratio of documents in which the word is present\n",
    "def create_doc_frequencies(data):\n",
    "  docFrequencies = {}\n",
    "  numDocuments = X_train.shape[0]\n",
    "  for word in stopwords:\n",
    "    docFrequency = 0\n",
    "    for text in data:\n",
    "      if word in text:\n",
    "        docFrequency += 1\n",
    "    docFrequencies[word] = docFrequency / numDocuments\n",
    "  return docFrequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFrequencies = create_doc_frequencies(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates tf-idf representations of given data from given document frequencies\n",
    "def create_tf_idf(data, docFrequencies):  \n",
    "  newData = []\n",
    "  docFrequenciesList = list(docFrequencies.values())\n",
    "  for text in data:\n",
    "    bag = [0] * stopwords_len\n",
    "    for word in text:\n",
    "      if word in stopwords:\n",
    "        bag[stopwords[word]] += 1 # bag of words representation\n",
    "    for i in range(len(bag)):\n",
    "      bag[i] = bag[i] / len(text) # term frequency representation\n",
    "      bag[i] = bag[i] * np.log(1 / docFrequenciesList[i]) # tf-idf representation\n",
    "    newData.append(bag)\n",
    "  return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = create_tf_idf(X_train, docFrequencies)\n",
    "X_val = create_tf_idf(X_val, docFrequencies)\n",
    "X_test = create_tf_idf(X_test, docFrequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation of the explained variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.apply(lambda x: genre_to_class[x])\n",
    "y_val = y_val.apply(lambda x: genre_to_class[x])\n",
    "y_test = y_test.apply(lambda x: genre_to_class[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_model():\n",
    "    input_layer = Input(shape=(stopwords_len,))\n",
    "    flatten = Flatten()(input_layer)\n",
    "    dense1 = Dense(1024, activation='relu')(flatten)\n",
    "    dropout1 = Dropout(rate=0.2)(dense1)\n",
    "    dense2 = Dense(1024, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(rate=0.2)(dense2)\n",
    "    concat = Concatenate()([dense1, dense2, dropout1, dropout2])\n",
    "    output_layer = Dense(5, activation='softmax')(concat)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DNN = func_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I used a checkpoint to load the scales at the highest validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model_checkpoint_DNN.keras',  # Path to save the model file with .keras extension\n",
    "    monitor='val_loss',                 # Metric to monitor\n",
    "    verbose=1,                          # Verbosity mode (0 or 1)\n",
    "    save_best_only=True,                # Only save the best model\n",
    "    mode='min',                         # Mode for the monitored metric\n",
    "    save_weights_only=False,            # Whether to save only the model weights\n",
    "    save_freq='epoch'                   # Save every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DNN.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_DNN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose = 1,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DNN.load_weights('model_checkpoint_DNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a predictions of given songs\n",
    "def predict_genre(model, songs):\n",
    "  songs = clean_data(songs)\n",
    "  songs = split_data(songs)\n",
    "  songs = stem(songs)\n",
    "  songs = remove_stopwords(songs)\n",
    "  songs = create_tf_idf(songs, docFrequencies)\n",
    "  songs = np.array(songs)\n",
    "  return model.predict(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre(model_DNN, ['Man, whatever\\nDre, just let it run\\nAyo, turn the beat up a little bit\\nAyo, this song is for anyone...\\nFuck it, just shut up and listen, ayo\\nI sit back with this pack of Zig-Zags and this bag\\nOf this weed, it gives me the shit needed to be\\nThe most meanest MC on this on this Earth\\nAnd since birth I\\'ve been cursed with this curse to just curse\\nAnd just blurt this berserk and bizarre shit that works\\nAnd it sells and it helps in itself to relieve all this tension\\nDispensing these sentences, getting this stress\\nThat\\'s been eating me recently off of this chest\\nAnd I rest again peacefully\\nBut at least have the decency in you\\nTo leave me alone, when you freaks see me out\\nIn the streets when I\\'m eating or feeding my daughter\\nTo not come and speak to me\\nI don\\'t know you, and no, I don\\'t owe you a mothafuckin\\' thing\\nI\\'m not Mr. N\\'Sync, I\\'m not what your friends think\\nI\\'m not Mr. Friendly, I can be a prick if you tempt me\\nMy tank is on empty, no patience is in me\\nAnd if you offend me, I\\'m lifting you ten feet in the air\\nI don\\'t care who was there and who saw me just jaw you\\nGo call you a lawyer, file you a lawsuit\\nI\\'ll smile in the courtroom and buy you a wardrobe\\nI\\'m tired of all you, I don\\'t mean to be mean\\nBut that\\'s all I can be, it\\'s just me\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am, huh\\nI don\\'t know, it\\'s just the way I am\\nSometimes I just feel like my father\\nI hate to be bothered with all of this nonsense, it\\'s constant\\nAnd, oh, it\\'s his lyrical content, the song Guilty Conscience\\nHas gotten such rotten responses\\nAnd all of this controversy circles me\\nAnd it seems like the media immediately points a finger at me\\nSo I point one back at \\'em, but not the index or pinkie\\nOr the ring or the thumb, it\\'s the one you put up\\nWhen you don\\'t give a fuck, when you won\\'t just put up\\nWith the bullshit they pull, \\'cause they full of shit too\\nWhen a dude\\'s getting bullied and shoots up his school\\nAnd they blame it on Marilyn and the heroin\\nWhere were the parents at? And look where it\\'s at!\\nMiddle America, now it\\'s a tragedy\\nNow it\\'s so sad to see, an upper-class city\\nHavin\\' this happenin\\'\\nThen attack Eminem \\'cause I rap this way\\nBut I\\'m glad, \\'cause they feed me the fuel that I need\\nFor the fire to burn and it\\'s burning, and I have returned\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am\\nI\\'m so sick and tired of being admired\\nThat I wish that I would just die or get fired\\nAnd dropped from my label, let\\'s stop with the fables\\nI\\'m not gonna be able to top on \"My Name Is\"\\nAnd pigeon-holed into some poppy sensation\\nTo cop me rotation at rock-n-roll stations\\nAnd I just do not got the patience\\nTo deal with these cocky Caucasians\\nWho think I\\'m some wigger who just tries to be black\\n\\'Cause I talk with an accent, and grab on my balls\\nSo they always keep asking the same fucking questions\\nWhat school did I go to, what hood I grew up in\\nThe why, the who, what, when, the where and the how\\n\\'Til I\\'m grabbing my hair and I\\'m tearin\\' it out\\n\\'Cause they driving me crazy, I can\\'t take it\\nI\\'m racin\\', I\\'m pacin\\', I stand and I sit\\nAnd I\\'m thankful for every fan that I get\\nBut I can\\'t take a shit in the bathroom\\nWithout someone standing by it\\nNo, I won\\'t sign you an autograph\\nYou can call me an asshole, I\\'m glad, \\'cause...\\nI am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelXGB = xgb.XGBClassifier()\n",
    "modelXGB.fit(X_train, y_train)\n",
    "\n",
    "preds = modelXGB.predict(X_val)\n",
    "accuracy_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre(modelXGB, ['Man, whatever\\nDre, just let it run\\nAyo, turn the beat up a little bit\\nAyo, this song is for anyone...\\nFuck it, just shut up and listen, ayo\\nI sit back with this pack of Zig-Zags and this bag\\nOf this weed, it gives me the shit needed to be\\nThe most meanest MC on this on this Earth\\nAnd since birth I\\'ve been cursed with this curse to just curse\\nAnd just blurt this berserk and bizarre shit that works\\nAnd it sells and it helps in itself to relieve all this tension\\nDispensing these sentences, getting this stress\\nThat\\'s been eating me recently off of this chest\\nAnd I rest again peacefully\\nBut at least have the decency in you\\nTo leave me alone, when you freaks see me out\\nIn the streets when I\\'m eating or feeding my daughter\\nTo not come and speak to me\\nI don\\'t know you, and no, I don\\'t owe you a mothafuckin\\' thing\\nI\\'m not Mr. N\\'Sync, I\\'m not what your friends think\\nI\\'m not Mr. Friendly, I can be a prick if you tempt me\\nMy tank is on empty, no patience is in me\\nAnd if you offend me, I\\'m lifting you ten feet in the air\\nI don\\'t care who was there and who saw me just jaw you\\nGo call you a lawyer, file you a lawsuit\\nI\\'ll smile in the courtroom and buy you a wardrobe\\nI\\'m tired of all you, I don\\'t mean to be mean\\nBut that\\'s all I can be, it\\'s just me\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am, huh\\nI don\\'t know, it\\'s just the way I am\\nSometimes I just feel like my father\\nI hate to be bothered with all of this nonsense, it\\'s constant\\nAnd, oh, it\\'s his lyrical content, the song Guilty Conscience\\nHas gotten such rotten responses\\nAnd all of this controversy circles me\\nAnd it seems like the media immediately points a finger at me\\nSo I point one back at \\'em, but not the index or pinkie\\nOr the ring or the thumb, it\\'s the one you put up\\nWhen you don\\'t give a fuck, when you won\\'t just put up\\nWith the bullshit they pull, \\'cause they full of shit too\\nWhen a dude\\'s getting bullied and shoots up his school\\nAnd they blame it on Marilyn and the heroin\\nWhere were the parents at? And look where it\\'s at!\\nMiddle America, now it\\'s a tragedy\\nNow it\\'s so sad to see, an upper-class city\\nHavin\\' this happenin\\'\\nThen attack Eminem \\'cause I rap this way\\nBut I\\'m glad, \\'cause they feed me the fuel that I need\\nFor the fire to burn and it\\'s burning, and I have returned\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am\\nI\\'m so sick and tired of being admired\\nThat I wish that I would just die or get fired\\nAnd dropped from my label, let\\'s stop with the fables\\nI\\'m not gonna be able to top on \"My Name Is\"\\nAnd pigeon-holed into some poppy sensation\\nTo cop me rotation at rock-n-roll stations\\nAnd I just do not got the patience\\nTo deal with these cocky Caucasians\\nWho think I\\'m some wigger who just tries to be black\\n\\'Cause I talk with an accent, and grab on my balls\\nSo they always keep asking the same fucking questions\\nWhat school did I go to, what hood I grew up in\\nThe why, the who, what, when, the where and the how\\n\\'Til I\\'m grabbing my hair and I\\'m tearin\\' it out\\n\\'Cause they driving me crazy, I can\\'t take it\\nI\\'m racin\\', I\\'m pacin\\', I stand and I sit\\nAnd I\\'m thankful for every fan that I get\\nBut I can\\'t take a shit in the bathroom\\nWithout someone standing by it\\nNo, I won\\'t sign you an autograph\\nYou can call me an asshole, I\\'m glad, \\'cause...\\nI am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DNN.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing between RNN and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates representations where every word is an integer of given data\n",
    "def integer_encoding(data):\n",
    "  newData = []\n",
    "  for text in data:\n",
    "    newText = []\n",
    "    for word in text:\n",
    "      if word not in vocab:\n",
    "        newText.append(1) # 1 is for word which is not in vocabulary\n",
    "      if word in vocab and vocab[word] > 0: # 0 is for empty word, we dont want that, 0 will be for padding\n",
    "        newText.append(vocab[word] + 1)\n",
    "    newData.append(newText)\n",
    "  return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = integer_encoding(X_train)\n",
    "X_val = integer_encoding(X_val)\n",
    "X_test = integer_encoding(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.apply(lambda x: genre_to_class[x])\n",
    "y_val = y_val.apply(lambda x: genre_to_class[x])\n",
    "y_test = y_test.apply(lambda x: genre_to_class[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts maximum length of given data\n",
    "def max_len(data):\n",
    "  maxLen = 0\n",
    "  for text in data:\n",
    "    if len(text) > maxLen:\n",
    "      maxLen = len(text)\n",
    "  return maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = max_len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxLen)\n",
    "X_val = sequence.pad_sequences(X_val, maxLen)\n",
    "X_test = sequence.pad_sequences(X_test, maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_model():\n",
    "  input_layer = Input(shape=(None,), dtype=\"int64\")\n",
    "  embedding = Embedding(vocabSize + 1, 64)(input_layer)\n",
    "  lstm = LSTM(64)(embedding)\n",
    "  output_layer = Dense(5, activation=\"softmax\")(lstm)\n",
    "  model = Model(inputs=input_layer, outputs=output_layer)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN = func_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/Model_Checkpoint/model_checkpoint_RNN.keras',  # Path to save the model file with .keras extension\n",
    "    monitor='val_accuracy',                 # Metric to monitor\n",
    "    save_best_only=True,                # Only save the best model\n",
    "    save_weights_only=False,            # Whether to save only the model weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_RNN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose = 1,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(model, songs):\n",
    "  songs = clean_data(songs)\n",
    "  songs = split_data(songs)\n",
    "  songs = stem(songs)\n",
    "  songs = remove_stopwords(songs)\n",
    "  songs = integer_encoding(songs)\n",
    "  songs = sequence.pad_sequences(songs, maxLen)\n",
    "  return model.predict(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre(model_RNN, ['Man, whatever\\nDre, just let it run\\nAyo, turn the beat up a little bit\\nAyo, this song is for anyone...\\nFuck it, just shut up and listen, ayo\\nI sit back with this pack of Zig-Zags and this bag\\nOf this weed, it gives me the shit needed to be\\nThe most meanest MC on this on this Earth\\nAnd since birth I\\'ve been cursed with this curse to just curse\\nAnd just blurt this berserk and bizarre shit that works\\nAnd it sells and it helps in itself to relieve all this tension\\nDispensing these sentences, getting this stress\\nThat\\'s been eating me recently off of this chest\\nAnd I rest again peacefully\\nBut at least have the decency in you\\nTo leave me alone, when you freaks see me out\\nIn the streets when I\\'m eating or feeding my daughter\\nTo not come and speak to me\\nI don\\'t know you, and no, I don\\'t owe you a mothafuckin\\' thing\\nI\\'m not Mr. N\\'Sync, I\\'m not what your friends think\\nI\\'m not Mr. Friendly, I can be a prick if you tempt me\\nMy tank is on empty, no patience is in me\\nAnd if you offend me, I\\'m lifting you ten feet in the air\\nI don\\'t care who was there and who saw me just jaw you\\nGo call you a lawyer, file you a lawsuit\\nI\\'ll smile in the courtroom and buy you a wardrobe\\nI\\'m tired of all you, I don\\'t mean to be mean\\nBut that\\'s all I can be, it\\'s just me\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am, huh\\nI don\\'t know, it\\'s just the way I am\\nSometimes I just feel like my father\\nI hate to be bothered with all of this nonsense, it\\'s constant\\nAnd, oh, it\\'s his lyrical content, the song Guilty Conscience\\nHas gotten such rotten responses\\nAnd all of this controversy circles me\\nAnd it seems like the media immediately points a finger at me\\nSo I point one back at \\'em, but not the index or pinkie\\nOr the ring or the thumb, it\\'s the one you put up\\nWhen you don\\'t give a fuck, when you won\\'t just put up\\nWith the bullshit they pull, \\'cause they full of shit too\\nWhen a dude\\'s getting bullied and shoots up his school\\nAnd they blame it on Marilyn and the heroin\\nWhere were the parents at? And look where it\\'s at!\\nMiddle America, now it\\'s a tragedy\\nNow it\\'s so sad to see, an upper-class city\\nHavin\\' this happenin\\'\\nThen attack Eminem \\'cause I rap this way\\nBut I\\'m glad, \\'cause they feed me the fuel that I need\\nFor the fire to burn and it\\'s burning, and I have returned\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am\\nI\\'m so sick and tired of being admired\\nThat I wish that I would just die or get fired\\nAnd dropped from my label, let\\'s stop with the fables\\nI\\'m not gonna be able to top on \"My Name Is\"\\nAnd pigeon-holed into some poppy sensation\\nTo cop me rotation at rock-n-roll stations\\nAnd I just do not got the patience\\nTo deal with these cocky Caucasians\\nWho think I\\'m some wigger who just tries to be black\\n\\'Cause I talk with an accent, and grab on my balls\\nSo they always keep asking the same fucking questions\\nWhat school did I go to, what hood I grew up in\\nThe why, the who, what, when, the where and the how\\n\\'Til I\\'m grabbing my hair and I\\'m tearin\\' it out\\n\\'Cause they driving me crazy, I can\\'t take it\\nI\\'m racin\\', I\\'m pacin\\', I stand and I sit\\nAnd I\\'m thankful for every fan that I get\\nBut I can\\'t take a shit in the bathroom\\nWithout someone standing by it\\nNo, I won\\'t sign you an autograph\\nYou can call me an asshole, I\\'m glad, \\'cause...\\nI am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_model():\n",
    "  input_layer = Input(shape=(None,), dtype=\"int64\")\n",
    "  embedding = Embedding(vocabSize + 1, 64)(input_layer)\n",
    "  conv1 = Conv1D(128, 5, activation=\"relu\")(embedding)\n",
    "  pool1 = MaxPooling1D(5)(conv1)\n",
    "  conv2 = Conv1D(128, 5, activation=\"relu\")(pool1)\n",
    "  pool2 = MaxPooling1D(5)(conv2)\n",
    "  conv3 = Conv1D(128, 5, activation=\"relu\")(pool2)\n",
    "  g_pool = GlobalMaxPooling1D()(conv3)\n",
    "  dense1 = Dense(128, activation=\"relu\")(g_pool)\n",
    "  dropout = Dropout(0.2)(dense1)\n",
    "  output_layer = Dense(5, activation=\"softmax\")(dropout)\n",
    "  model = Model(inputs=input_layer, outputs=output_layer)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN = func_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/Model_checkpoint/model_checkpoint_CNN.keras',  # Path to save the model file with .keras extension\n",
    "    monitor='val_loss',                 # Metric to monitor\n",
    "    verbose=1,                          # Verbosity mode (0 or 1)\n",
    "    save_best_only=True,                # Only save the best model\n",
    "    mode='min',                         # Mode for the monitored metric\n",
    "    save_weights_only=False,            # Whether to save only the model weights\n",
    "    save_freq='epoch'                   # Save every epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_CNN.fit(X_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose = 1,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.load_weights('model_checkpoint_CNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre(model_CNN, ['Man, whatever\\nDre, just let it run\\nAyo, turn the beat up a little bit\\nAyo, this song is for anyone...\\nFuck it, just shut up and listen, ayo\\nI sit back with this pack of Zig-Zags and this bag\\nOf this weed, it gives me the shit needed to be\\nThe most meanest MC on this on this Earth\\nAnd since birth I\\'ve been cursed with this curse to just curse\\nAnd just blurt this berserk and bizarre shit that works\\nAnd it sells and it helps in itself to relieve all this tension\\nDispensing these sentences, getting this stress\\nThat\\'s been eating me recently off of this chest\\nAnd I rest again peacefully\\nBut at least have the decency in you\\nTo leave me alone, when you freaks see me out\\nIn the streets when I\\'m eating or feeding my daughter\\nTo not come and speak to me\\nI don\\'t know you, and no, I don\\'t owe you a mothafuckin\\' thing\\nI\\'m not Mr. N\\'Sync, I\\'m not what your friends think\\nI\\'m not Mr. Friendly, I can be a prick if you tempt me\\nMy tank is on empty, no patience is in me\\nAnd if you offend me, I\\'m lifting you ten feet in the air\\nI don\\'t care who was there and who saw me just jaw you\\nGo call you a lawyer, file you a lawsuit\\nI\\'ll smile in the courtroom and buy you a wardrobe\\nI\\'m tired of all you, I don\\'t mean to be mean\\nBut that\\'s all I can be, it\\'s just me\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am, huh\\nI don\\'t know, it\\'s just the way I am\\nSometimes I just feel like my father\\nI hate to be bothered with all of this nonsense, it\\'s constant\\nAnd, oh, it\\'s his lyrical content, the song Guilty Conscience\\nHas gotten such rotten responses\\nAnd all of this controversy circles me\\nAnd it seems like the media immediately points a finger at me\\nSo I point one back at \\'em, but not the index or pinkie\\nOr the ring or the thumb, it\\'s the one you put up\\nWhen you don\\'t give a fuck, when you won\\'t just put up\\nWith the bullshit they pull, \\'cause they full of shit too\\nWhen a dude\\'s getting bullied and shoots up his school\\nAnd they blame it on Marilyn and the heroin\\nWhere were the parents at? And look where it\\'s at!\\nMiddle America, now it\\'s a tragedy\\nNow it\\'s so sad to see, an upper-class city\\nHavin\\' this happenin\\'\\nThen attack Eminem \\'cause I rap this way\\nBut I\\'m glad, \\'cause they feed me the fuel that I need\\nFor the fire to burn and it\\'s burning, and I have returned\\nAnd I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am\\nI\\'m so sick and tired of being admired\\nThat I wish that I would just die or get fired\\nAnd dropped from my label, let\\'s stop with the fables\\nI\\'m not gonna be able to top on \"My Name Is\"\\nAnd pigeon-holed into some poppy sensation\\nTo cop me rotation at rock-n-roll stations\\nAnd I just do not got the patience\\nTo deal with these cocky Caucasians\\nWho think I\\'m some wigger who just tries to be black\\n\\'Cause I talk with an accent, and grab on my balls\\nSo they always keep asking the same fucking questions\\nWhat school did I go to, what hood I grew up in\\nThe why, the who, what, when, the where and the how\\n\\'Til I\\'m grabbing my hair and I\\'m tearin\\' it out\\n\\'Cause they driving me crazy, I can\\'t take it\\nI\\'m racin\\', I\\'m pacin\\', I stand and I sit\\nAnd I\\'m thankful for every fan that I get\\nBut I can\\'t take a shit in the bathroom\\nWithout someone standing by it\\nNo, I won\\'t sign you an autograph\\nYou can call me an asshole, I\\'m glad, \\'cause...\\nI am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nRadio won\\'t even play my jam\\n\\'Cause I am whatever you say I am\\nIf I wasn\\'t, then why would I say I am?\\nIn the paper, the news, every day I am\\nI don\\'t know, it\\'s just the way I am'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
